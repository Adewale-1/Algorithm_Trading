import requests
from transformers import GPT2Tokenizer, GPT2LMHeadModel

# Initialize the tokenizer and model from the transformers (you can replace it with GPT-4 once available)
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')


def fetch_news(api_key, q, from_date, to_date, language='en'):
    url = f'https://newsapi.org/v2/everything?q={q}&from={from_date}&to={to_date}&language={language}&apiKey={api_key}'
    response = requests.get(url)
    articles = response.json()['articles']
    return articles


def get_sentiment(text):
    inputs = tokenizer.encode(text, return_tensors='pt')
    outputs = model.generate(inputs)
    text_generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
    # Parse the sentiment from the text_generated by GPT-4's return
    # For now it's mockup, as we don't have the exact way GPT-4 outputs sentiment
    sentiment = parse_gpt_output(text_generated)
    return sentiment


def parse_gpt_output(output):
    # Mockup sentiment parsing, you would need actual sentiment parsing logic here
    # Assume GPT-4 outputs a sentence indicating positive or negative sentiment
    if 'positive' in output:
        return 1  # Positive sentiment
    elif 'negative' in output:
        return -1  # Negative sentiment
    else:
        return 0  # Neutral sentiment


# Example usage
api_key = '11304ff0ba084d26b6d40f1da150e3c9'  # Add your NewsAPI key here
articles = fetch_news(api_key, 'EURUSD', '2023-01-01', '2023-04-01')

# Get sentiment for each article
for article in articles:
    # Assume 'content' field contains the text
    sentiment = get_sentiment(article['content'])
    print(f"Sentiment for article '{article['title']}': {sentiment}")
